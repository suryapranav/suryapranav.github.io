<!DOCTYPE html>
<html>

<head>
    
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">

<title>
    GitHub Copilot - Surya&rsquo;s Website
</title>









<link rel="stylesheet" href="/css/main.min.c5514d3530979d291f3497facc20da1cec870028dbc2a3630b64bab8721bbe49.css" integrity="sha256-xVFNNTCXnSkfNJf6zCDaHOyHACjbwqNjC2S6uHIbvkk=" crossorigin="anonymous" media="screen">




  






<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Didact+Gothic">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="GitHub Copilot"/>
<meta name="twitter:description" content="GitHub Copilot&nbsp;¶What Copilot is&nbsp;¶Microsoft-owned GitHub has caused quite a bit of commotion in the software scene [free or otherwise] with the announcement of GitHub Copilot, an ML using extension for Visual Studio Code trained on code from public repositories on the site. While software assistance for developers is not a remotely new concept, Copilot differs from other services in its ability to create multiple lines, even entire functions of code based on the name of a function and the developers&#39; comments."/>

<meta property="og:title" content="GitHub Copilot" />
<meta property="og:description" content="GitHub Copilot&nbsp;¶What Copilot is&nbsp;¶Microsoft-owned GitHub has caused quite a bit of commotion in the software scene [free or otherwise] with the announcement of GitHub Copilot, an ML using extension for Visual Studio Code trained on code from public repositories on the site. While software assistance for developers is not a remotely new concept, Copilot differs from other services in its ability to create multiple lines, even entire functions of code based on the name of a function and the developers&#39; comments." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://suryapranav.github.io/posts/copilot/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-09-25T08:59:54+05:30" />
<meta property="article:modified_time" content="2021-09-25T08:59:54+05:30" />



    

    
    
    
    <title>
        
        GitHub Copilot
        
    </title>
</head>

<body>
    
    
    <header class="wrap flex-container">
        <h1>GitHub Copilot</h1>
    </header>
    
    <main class="wrap">
        
<div class="flex-container">
    <aside role="complementary">
        Sat Sep 25, 2021 &#183; 1670 words
        <div class="tag-container">
            
        </div>
    </aside>
    <hr />
    <article role="article">
        
<h1 id="github-copilot" class="anchor-link"><a href="#github-copilot"><em>GitHub</em> Copilot<span class="pilcrow">&nbsp;¶</span></a></h1>

<h2 id="what-copilot-is" class="anchor-link"><a href="#what-copilot-is">What <em>Copilot</em> is<span class="pilcrow">&nbsp;¶</span></a></h2>
<p>Microsoft-owned <em>GitHub</em> has caused quite a bit of commotion in the
software scene [free or otherwise] with the announcement of <em>GitHub
Copilot</em>, an ML using extension for Visual Studio Code trained on code
from public repositories on the site. While software assistance for
developers is not a remotely new concept, Copilot differs from other
services in its ability to create multiple lines, even entire functions
of code based on the name of a function and the developers' comments.
From the demos and previews on the copilot website, the description
&ldquo;pair programmer&rdquo; isn&rsquo;t all that inaccurate.</p>
<p><p style="text-align:center;">
    <img src="https://suryapranav.github.io/data/copilotgif.gif" alt=""  />
</p>
</p>

<h2 id="how-does-it-work" class="anchor-link"><a href="#how-does-it-work">How does it work?<span class="pilcrow">&nbsp;¶</span></a></h2>
<p>The service is currently available in a technical preview, so things
might change- but fundamentally, Copilot uses OpenAI models [trained
from <em>GitHub</em> code] to find the best match for the comments and the
function name provided to it by the IDE.</p>
<p><p style="text-align:center;">
    <img src="https://suryapranav.github.io/data/copilot.png" alt=""  />
</p>
</p>

<h2 id="is-this-legal" class="anchor-link"><a href="#is-this-legal">Is this <em>legal</em>?<span class="pilcrow">&nbsp;¶</span></a></h2>
<p>There are two main points in the flow of data with the service that have
an ambiguous legal status:</p>
<ul>
<li>Firstly what would happen if the code from public repositories is
licensed under a strong copyleft license [one which may require
credit to be given to the original author if the code is reused].
Should Copilot have to comply with the licenses for processing code?
[Exploring the legality of <em>training</em> the AI.]</li>
<li>And second, whether or not the &ldquo;machine-generated&rdquo; code is actually
a derivative of the input code given to the AI. Should the users
using Copilot have to follow the restrictions of the licenses of the
training code on their own code? [Exploring the legality of <em>using</em>
the AI.]</li>
</ul>

<h3 id="is-training-copilot-legal" class="anchor-link"><a href="#is-training-copilot-legal">Is <em>training</em> Copilot legal?<span class="pilcrow">&nbsp;¶</span></a></h3>
<p>This should come as no surprise, but the latest project of a
trillion-dollar corporation, is, in fact, legal. Ignoring ethical
concerns, <a href="https://www.docs.github.com/en/github/site-policy/github-terms-of-service#4-license-grant-to-us">this
section</a>
of the <em>GitHub</em> terms of service grants GitHub the right to use your
code- <strong>regardless of license</strong>.</p>
<p>This means that the first point holds no validity as long as Copilot is
trained using only the code hosted on <em>GitHub</em>. Even in the case that
this foreign code is used, the case could be made for the use of this
code is <em>transformative</em>, and possibly under the scope of fair use.</p>
<p>GitHub is safe here, as predicted by its CEO in <a href="https://www.twitter.com/natfriedman/status/1409914420579344385">this
tweet</a>.</p>

<h3 id="is-using-copilot-legal" class="anchor-link"><a href="#is-using-copilot-legal">Is <em>Using</em> Copilot legal?<span class="pilcrow">&nbsp;¶</span></a></h3>
<p>However, the second point is more interesting. In theory, the AI is
supposed to <em>understand</em> public code to synthesize its own code based on
its <em>understanding</em> of the code. Shown by <a href="https://www.docs.github.com/en/github/copilot/research-recitation">this case
study</a>,
it <em>is</em> possible for the AI to reuse code from the public repos,
verbatim.</p>
<p>A hilarious example of this is Copilot&rsquo;s attempt to write an about-me
page, on which request <a href="https://www.twitter.com/davidcelis/status/1410749792825737219?s=20">it output the exact <em>GitHub</em> bio of user David
Celis</a>,
and another where the code is taken word-for-word from the <a href="https://twitter.com/mitsuhiko/status/1410886329924194309?s=20">Quake III
game, including the swear-y
comments</a>.</p>
<p>This means that however rarely, [GitHub published that the rate at
which this happens is around 0.1%, and is more common on files where
Copilot is given little to no information, or just empty files.] it&rsquo;s
still possible for code to be reused with no transformation, and this is
the situation with the highest legal ambiguity.</p>
<p><em>GitHub</em>&rsquo;s explanation for this is:</p>
<blockquote>
<p>This investigation demonstrates that <em>GitHub</em> Copilot can quote a body
of code verbatim, but that it rarely does so, and when it does, it
mostly quotes code that everybody quotes, and mostly at the beginning
of a file, as if to break the ice.
<a href="https://www.docs.github.com/en/github/copilot/research-recitation"><strong>source</strong></a></p>
</blockquote>
<p><p style="text-align:center;">
    <img src="https://suryapranav.github.io/data/graph.png" alt=""  />
</p>
</p>
<p>Ultimately, it&rsquo;s not easy to determine exactly <em>what</em> this code is- and
whether or not it&rsquo;s &ldquo;machine-generated&rdquo;. This is more important that it
seems, especially for developers. For instance, code that is derived or
forked from a <a href="https://www.twitter.com/eevee/status/1410037309848752128">project licensed
GPLv3</a> is
legally also supposed to be licensed under the same GPLv3 license. Worse
case scenario? This means that programmers might unintentionally give up
their freedom in licensing their software.</p>
<p>That&rsquo;s just the worse case scenario, however- because copyright laws are
a little more complicated. Julia Reda, a legislator at the EU writes:</p>
<blockquote>
<p>[…]it suggests that even reproducing the smallest excerpts of
protected works constitutes copyright infringement. This is not the
case. Such use is only relevant under copyright law if the excerpt
used is in turn original and unique enough to reach the threshold of
originality[…] The short code snippets that Copilot reproduces from
training data are unlikely to reach the threshold of originality.
<a href="https://www.juliareda.eu/2021/07/github-copilot-is-not-infringing-your-copyright/"><strong>source</strong></a></p>
</blockquote>
<p>This is just speculation, though. There are
<a href="https://www.fossa.com/blog/analyzing-legal-implications-github-copilot/">conflicti</a><a href="https:/medium.com/geekculture/githubs-ai-copilot-might-get-you-sued-if-you-use-it-c1cade1ea229">ng
opinions</a>
from other legal experts- and only predictions can be made until a
judge&rsquo;s verdict is made, after the release of the software. The most
concerning factor, to me personally, is that the law might not be
equipped to properly deal with <em>GitHub</em> copilot. This project is the
first of its kind- and the legislation that such a program has to be put
under is still unclear. This makes it all too easy to make an
insufficient or even incorrect judgement, and worse yet, this is the
link on the chain furthest from the control of the average person like
you or me. We can only hope that legislators are able to grasp the
nuance and difficulty in categorizing such an innovative, out-of-the-box
idea.</p>

<h2 id="is-this-ethical" class="anchor-link"><a href="#is-this-ethical">Is this <em>ethical</em>?<span class="pilcrow">&nbsp;¶</span></a></h2>
<p>As fun as it is for me to point at the rule book and scream &ldquo;That&rsquo;s not
enough!&rdquo; or &ldquo;That&rsquo;s Kafkaesque!&rdquo;, the moral and philosophical issues are
probably more important here. They&rsquo;re also pretty straightforward:</p>
<blockquote>
<p>Is it ethical to use free/open-source code to make a proprietary service?</p>
</blockquote>
<p>After all, <em>GitHub</em> copilot trains on a heap of FOSS code, but the end
product of this training is a closed-source, paid-for product. While
this is clearly the most important issue, it&rsquo;s not one that I&rsquo;m
qualified to pass judgment on. I believe that this is part of the
reasoning for a programmer to pick a particular license [for instance,
how <em>GPLv2</em> or <em>WTFPL</em> permit this, but the more popular <em>GPLv3</em> does
not]. As a consequence of this belief, I think it&rsquo;s completely
unethical for <em>GitHub</em> to ignore the choices of developers just because
of a vague clause in their terms of service, that most would not expect
to be used this way anyway. However, it&rsquo;s not all bad. <em>GitHub</em>
acknowledges the choice of the end user to determine if the source of
code is okay to be used in their project, and write this:</p>
<blockquote>
<p>The answer is obvious: sharing the prefiltering solution we used in
this analysis to detect overlap with the training set. When a
suggestion contains snippets copied from the training set, the UI
should simply tell you where it&rsquo;s quoted from. You can then either
include proper attribution or decide against using that code
altogether.
<a href="https://www.docs.github.com/en/github/copilot/research-recitation#conclusion-and-next-steps"><strong>source</strong></a></p>
</blockquote>

<h2 id="other-issues-with-copilot" class="anchor-link"><a href="#other-issues-with-copilot">Other issues with copilot<span class="pilcrow">&nbsp;¶</span></a></h2>

<h3 id="copilot-is-not-free-software" class="anchor-link"><a href="#copilot-is-not-free-software">Copilot is not free software<span class="pilcrow">&nbsp;¶</span></a></h3>
<p>There are many other &ldquo;issues&rdquo; regarding copilot-and not just about
legality- some of which the Free Software Foundation has published
<a href="https://www.www.fsf.org/blogs/licensing/fsf-funded-call-for-white-papers-on-philosophical-and-legal-uestions-around-copilot">here</a>.
The FSF requests developers not to use the service, citing its
dependencies on proprietary software (particularly VSCode). The FSF also
recommends <a href="https://www.gnu.org/software/repo-criteria%20evaluation.html#/GitHub/">doing away with GitHub
entirely</a>.</p>

<h3 id="copilot-is-biased" class="anchor-link"><a href="#copilot-is-biased">Copilot is biased<span class="pilcrow">&nbsp;¶</span></a></h3>
<p>Perhaps as an artifact of being trained mostly from one source, Copilot
might have inherent biases and inefficiencies- as pointed out by <a href="https://www.arxiv.org/pdf/2107.03374.pdf">this
paper</a>. In the words of Kyle
Wiggers:</p>
<blockquote>
<p>After repeated sampling from the model, where Codex was given 100
samples per problem, OpenAI says it manages to answer 70.2% of the
HumanEval challenges correctly. But the company&rsquo;s researchers also
found that Codex proposes syntactically incorrect or undefined code,
invoking functions, variables, and attributes that are undefined or
outside the scope of the codebase.
<a href="https://www.venturebeat.com/2021/07/08/openai-warns-ai-behind-githubs-copilot-may-be-susceptible-to-bias/"><strong>source</strong></a></p>
</blockquote>
<p>My personal bet as to why this might be is simple: Garbage in, garbage
out. Copilot is not trained on high-quality code, but rather from
popular repositories on <em>GitHub</em> with up to hundreds of contributors
each- and not all of these files are full of high-quality code. In other
words, <em>garbage in, garbage out</em>. It&rsquo;s possible to tune the training
dataset go get rid of redundant code, but it&rsquo;s a lot of work: and
<em>mannual, human work</em> at that. I&rsquo;d only expect the quality of code to go
up <em>after</em> launch, when bad code is rejected by the users, giving the AI
a chance to analyze what kind of code is accepted more often.</p>

<h3 id="copilot-might-not-be-useful" class="anchor-link"><a href="#copilot-might-not-be-useful">Copilot might not be <em>useful</em>?<span class="pilcrow">&nbsp;¶</span></a></h3>
<p><p style="text-align:center;">
    <img src="https://suryapranav.github.io/data/IntelliCodeUsageExamples.gif" alt=""  />
</p>
</p>
<p>I&rsquo;ve been going on about the legal implications of this product, mainly
because it seemed very interesting to me [and also because I&rsquo;m not
qualified or experienced enough to discuss the user experience]- but
the elephant in the room is obviously the actual utility of this
service… which seems to be hit or miss.</p>
<p><a href="https://www.www.fast.ai/2021/07/19/copilot/">This article</a> (that I
highly recommend you read), written by a co-author of the paper that
inspired the creation of the <em>Codex</em> backend of Copilot, claims that the
dips in quality of code might be due to the behavior of the code
algorithms. He even calls Copilot &ldquo;[…] <em>worse</em> than the average
programmer [in some ways]&rdquo;, referring to how unlike humans, Copilot&rsquo;s
entire knowledge comes from public code, with no regard to
documentation, compiler warnings, et cetera.</p>
<blockquote>
<p>The thing to remember is that Copilot is an early preview of a very
new technology that&rsquo;s going to get better and better. There will be
many competitors popping up in the coming months and years, and
<em>GitHub</em> will no doubt release new and better versions of their own
tool.</p>
</blockquote>

<h2 id="conclusion" class="anchor-link"><a href="#conclusion">Conclusion<span class="pilcrow">&nbsp;¶</span></a></h2>
<p>Obviously, Copilot has its flaws. Duh. But like Jeremy Howard writes…</p>
<blockquote>
<p>Complaining about the quality of the code written by Copilot feels a
bit like coming across a talking dog, and complaining about its
diction. The fact that it&rsquo;s talking at all is impressive enough!</p>
</blockquote>
<p>Truly, <em>GitHub</em> Copilot is a step forward for programmers. Contesting
<em>if</em> it should exist is out of the question. Really, the only question
here is <em>how</em> it should be implemented- and I think that most of the
flaws will be ironed out with time. I&rsquo;m nothing but excited to see the
effects of such a program, and I hope it reduces the barrier to
programming!</p>

    </article>
</div>


        
<nav role="navigation" class="flex-container bottom-menu">
    
<hr />
<p>


    
        <a href="/posts">back</a>
        
            &#183;
        
    

    
        
            <a href="/posts">/writing/</a>
        
    
    
        
            &#183; 
            <a href="/about-me">/interests/</a>
        
            &#183; 
            <a href="/intro">/about-me/</a>
        
    
    
    

</p>
</nav>

    </main>
    
    <footer class="flex-container footer">
</footer>
    
    
</body>

</html>